{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эта тетрадка даёт лучший скор, хоть на мой взгляд для этого не нужно много делать, т.к. пользоваться предобученными моделями с `huggingface` крайне просто. Так же пробовал линейные классификаторы, байесовские классификаторы, самописный `LSTM` на предобученных эмбедингах `fasttext` от команды `DeepPavlov`, всё показывало качество значительно хуже чем предобученные трансформеры.  \n",
    "\n",
    "Так же пробовал обучаться напрямую на дифференциируемый аналог F1 в качестве лосса, но похоже из-за того, что баланс классов 50/50, здесь такой лосс не подойдет, т.к. градиенты по лоссу для объектов нулевого класса почти нулевые, и из-за этого предсказать единицы правильно гораздо важнее с точки зрения лосса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T19:45:28.132550Z",
     "iopub.status.busy": "2022-04-24T19:45:28.131954Z",
     "iopub.status.idle": "2022-04-24T19:45:47.039021Z",
     "shell.execute_reply": "2022-04-24T19:45:47.038296Z",
     "shell.execute_reply.started": "2022-04-24T19:45:28.132449Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "\n",
    "from datasets import load_metric\n",
    "from datasets import load_dataset\n",
    "\n",
    "TRAIN_DATA_PATH = '../input/fakenews/train.tsv' #путь к файлу трейна на диске\n",
    "TEST_DATA_PATH = '../input/fakenews/test.tsv' #путь к файлу теста на диске\n",
    "AUG_DATA_PATH = '../input/fakenews/augmented_train.csv' #путь к файлу с аугментациями\n",
    "MODEL_NAME = 'DeepPavlov/rubert-base-cased-sentence' #название предобученной модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для максимальной воспроизводимости фиксируем сиды."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T19:45:47.040873Z",
     "iopub.status.busy": "2022-04-24T19:45:47.040593Z",
     "iopub.status.idle": "2022-04-24T19:45:47.107210Z",
     "shell.execute_reply": "2022-04-24T19:45:47.106529Z",
     "shell.execute_reply.started": "2022-04-24T19:45:47.040834Z"
    }
   },
   "outputs": [],
   "source": [
    "def seed_all(seed_value):\n",
    "    random.seed(seed_value) \n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value) \n",
    "    if torch.cuda.is_available() :\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value) \n",
    "        torch.backends.cudnn.deterministic = True \n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        \n",
    "seed_all(21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для аугментации текста была использована библиотка `nlpaug`, метод - перевод текста на другой язык и обратно. Т.к. процесс занимает много времени, в архиве прикладываю сразу файл 'train_augmented.csv'. С кодом, выполняющим аугментацию, можно ознакомиться ниже (в аргументах класса `BackTranslationAug` указываем две модели с `huggingface`, которые будут выполнять перевод между языками).\n",
    "\n",
    "Так же пробовал аугментации в виде замены слов на близкие по смыслу (контекстные эмбеддинги из моделей трансформеров) и случайную перестановку слов в предложении, оба метода приводили к ухудшению качества."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T19:45:47.109085Z",
     "iopub.status.busy": "2022-04-24T19:45:47.108638Z",
     "iopub.status.idle": "2022-04-24T19:45:47.112984Z",
     "shell.execute_reply": "2022-04-24T19:45:47.112140Z",
     "shell.execute_reply.started": "2022-04-24T19:45:47.109048Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/makcedward/nlpaug.git\n",
    "# import nlpaug\n",
    "# import nlpaug.augmenter.word as naw\n",
    "\n",
    "# text = 'Каждый охотник желает знать, где сидит фазан.'\n",
    "\n",
    "# back_translation_aug = naw.BackTranslationAug(\n",
    "#     from_model_name='Helsinki-NLP/opus-mt-ru-en', \n",
    "#     to_model_name='Helsinki-NLP/opus-mt-en-ru',\n",
    "#     device='cuda'\n",
    "# )\n",
    "\n",
    "# back_translation_aug.augment(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подгружаем данные (мерджим исходный трейн файл и файл с аугментациями, плюс переводим все в .csv т.к. `huggingface` не дружит с .tsv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T19:45:47.115706Z",
     "iopub.status.busy": "2022-04-24T19:45:47.115215Z",
     "iopub.status.idle": "2022-04-24T19:45:47.244253Z",
     "shell.execute_reply": "2022-04-24T19:45:47.243577Z",
     "shell.execute_reply.started": "2022-04-24T19:45:47.115647Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_csvs():\n",
    "    news = pd.read_csv(TRAIN_DATA_PATH, sep='\\t')\n",
    "    news_test = pd.read_csv(TEST_DATA_PATH, sep='\\t')\n",
    "    news_augmented = pd.read_csv(AUG_DATA_PATH)\n",
    "    \n",
    "    news_train = pd.concat([news_augmented, news])\n",
    "    news_train.to_csv('train.csv', index=False)\n",
    "    news_test.to_csv('test.csv', index=False)\n",
    "\n",
    "get_csvs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем датасеты с помощью библиотеки `datasets` от `huggingface`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T19:45:47.247060Z",
     "iopub.status.busy": "2022-04-24T19:45:47.246632Z",
     "iopub.status.idle": "2022-04-24T19:45:48.250735Z",
     "shell.execute_reply": "2022-04-24T19:45:48.250054Z",
     "shell.execute_reply.started": "2022-04-24T19:45:47.247019Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_datasets():\n",
    "    train_dataset = load_dataset('csv', data_files='./train.csv')['train']\n",
    "    test_dataset = load_dataset('csv', data_files='./test.csv')['train']\n",
    "    \n",
    "    train_dataset = train_dataset.rename_column(\"title\", \"text\")\n",
    "    train_dataset = train_dataset.rename_column(\"is_fake\", \"label\")\n",
    "    test_dataset = test_dataset.rename_column(\"title\", \"text\")\n",
    "    test_dataset = test_dataset.remove_columns('is_fake')\n",
    "    \n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "train_dataset, test_dataset = get_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подгружаем предобученные модели и токенайзер, я остановился на предобученной модели `rubert-base-cased-sentence` от команды `DeepPavlov`. Используем класс `AutoModelForSequenceClassification` и указываем нужное количество классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T19:45:48.252662Z",
     "iopub.status.busy": "2022-04-24T19:45:48.251963Z",
     "iopub.status.idle": "2022-04-24T19:46:12.417883Z",
     "shell.execute_reply": "2022-04-24T19:46:12.417237Z",
     "shell.execute_reply.started": "2022-04-24T19:45:48.252625Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Токенизируем наши тексты и удаляем колонку с ними (результаты токенизации будут записаны в другие колонки).  \n",
    "Не объявляем здесь паддинг, т.к. в цикле обучении будет сделан паддинг по каждому батчу до длины наиболее длинного экземпляра в батче, а не целиком для всего датасета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T19:46:12.419213Z",
     "iopub.status.busy": "2022-04-24T19:46:12.418967Z",
     "iopub.status.idle": "2022-04-24T19:46:16.255409Z",
     "shell.execute_reply": "2022-04-24T19:46:16.254739Z",
     "shell.execute_reply.started": "2022-04-24T19:46:12.419178Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_function(data):\n",
    "    return tokenizer(data[\"text\"])\n",
    "\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function)\n",
    "tokenized_test_dataset = test_dataset.map(tokenize_function)\n",
    "\n",
    "tokenized_train_dataset = tokenized_train_dataset.remove_columns('text')\n",
    "tokenized_test_dataset = tokenized_test_dataset.remove_columns('text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подгружаем метрику F1 для валидации и пишем функцию для ее вычисления по выходам модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T19:46:16.257054Z",
     "iopub.status.busy": "2022-04-24T19:46:16.256802Z",
     "iopub.status.idle": "2022-04-24T19:46:16.884317Z",
     "shell.execute_reply": "2022-04-24T19:46:16.883664Z",
     "shell.execute_reply.started": "2022-04-24T19:46:16.257019Z"
    }
   },
   "outputs": [],
   "source": [
    "metric = load_metric(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем класс `TrainingArguments` в который записываем параметры для обучения, который потом передадим инстансу класса `Trainer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T19:46:16.885742Z",
     "iopub.status.busy": "2022-04-24T19:46:16.885421Z",
     "iopub.status.idle": "2022-04-24T19:46:18.831688Z",
     "shell.execute_reply": "2022-04-24T19:46:18.830878Z",
     "shell.execute_reply.started": "2022-04-24T19:46:16.885702Z"
    }
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=7,              \n",
    "    per_device_train_batch_size=4,   \n",
    "    per_device_eval_batch_size=64,   \n",
    "    learning_rate=1e-5,\n",
    "    evaluation_strategy='epoch',\n",
    "    logging_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    save_total_limit=1,\n",
    "    seed=21,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объявляем `Trainer` и запускаем обучение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T19:46:18.835280Z",
     "iopub.status.busy": "2022-04-24T19:46:18.835012Z",
     "iopub.status.idle": "2022-04-24T20:11:31.965309Z",
     "shell.execute_reply": "2022-04-24T20:11:31.964469Z",
     "shell.execute_reply.started": "2022-04-24T19:46:18.835243Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args, #аргументы\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_train_dataset, #для валидации датасета нет\n",
    "    compute_metrics=compute_metrics #метрики\n",
    ")\n",
    "\n",
    "trained = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для получения меток классов и сохранение в файл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T20:13:33.466586Z",
     "iopub.status.busy": "2022-04-24T20:13:33.465918Z",
     "iopub.status.idle": "2022-04-24T20:13:34.587198Z",
     "shell.execute_reply": "2022-04-24T20:13:34.586576Z",
     "shell.execute_reply.started": "2022-04-24T20:13:33.466550Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_test_labels():\n",
    "    test_predictions = trainer.predict(tokenized_test_dataset)\n",
    "    labels = np.argmax(test_predictions.predictions, axis=-1)    \n",
    "    return labels\n",
    "\n",
    "def save_test_predictions():\n",
    "    news_test = pd.read_csv(TEST_DATA_PATH, sep='\\t')\n",
    "    news_test.is_fake = get_test_labels()\n",
    "    news_test.to_csv('predictions.tsv', sep='\\t', index=False)\n",
    "    \n",
    "save_test_predictions()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
